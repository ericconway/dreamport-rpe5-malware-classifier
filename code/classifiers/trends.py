from collections import Counter, defaultdict
import itertools
import random

__version__ = '0.1'
__enabled__ = False


"""
print most common features found for each label
"""

def run(filepath='', fileinfo=None, storage=None, file_data=None, mode='learn', train_percent=100, rand_seed='0', **kwargs):

    if mode == 'learn':
        return learn(storage, train_percent, rand_seed)
    else:
        return None


def file_is_for_training(md5, train_percent, rand_seed):
    random.seed(md5+rand_seed)
    return 100.0 * random.random() < train_percent


def learn(storage, train_percent, rand_seed):

    # load all feature data we have collected
    print('loading all data')
    all_features = storage.load_all('features')

    feature_db = defaultdict(lambda: defaultdict(Counter))
    # organized: [plugin_name] [label_k:label_v]  count number of files feature appears in

    for file_data in all_features:

        if not file_data:
            continue

        if train_percent < 100:
            # only use some files
            if not file_is_for_training(file_data['fileinfo']['md5'], train_percent, rand_seed):
                # skip here, use this file in test instead
                continue

        # only consider files that are labeled in some way
        if 'labels' in file_data['fileinfo']:
            if file_data['fileinfo']['labels'] is not None:

                # loop over labels
                for label_k, label_v in file_data['fileinfo']['labels'].items():

                    # loop over plugins
                    for plugin_data in file_data['plugins']:

                        feature_db[plugin_data['plugin']][label_k+':'+label_v].update(plugin_data['results'].keys())

    for plugin_name in feature_db:
        for label in feature_db[plugin_name]:
            top = feature_db[plugin_name][label].most_common(10)
            print(plugin_name+':'+label+':')
            for k,c in top:
                print('  '+k)


    #storage.store('classifiers', __name__, data=classifiers, fmt='pickle')

