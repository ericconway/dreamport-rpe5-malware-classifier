import collections
import re
import subprocess
import sys

__version__ = '0.1'
__enabled__ = True

RUN_RABIN = True
RUN_CLAM = True


# TODO text files: line ending, encoding, indentation none/tab/space/mixed, commenting, keywords for javascript/html, base64, regex email/url/ip/guid/etc
# TODO RichPE

def run(filepath='', fileinfo=None, **kwargs):
    print("    %s.run()" % __name__)

    features = collections.Counter()
    if RUN_RABIN:
        features += run_rabin(filepath, fileinfo)
    if RUN_CLAM:
        features += run_clam(filepath, fileinfo)
    return features


def run_rabin(filepath, fileinfo=None):
    """
    Run "rabin2" from Radare2 and scrape output.
    Tested with radare2 version 3.6.0
    """

    features = collections.Counter()

    if fileinfo:
        if 'type' in fileinfo:
            unsupported = ['text', 'archive', 'data']
            if any([u in fileinfo['type'] for u in unsupported]):
                return features

    cmd = ['rabin2', '-g', filepath]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    for line in stderr.splitlines() + stdout.splitlines():
        line = line.decode('utf-8', errors='replace').strip()

        # skip headers
        if line.startswith('[') and line.endswith(']'):
            continue
        if line.startswith('Num  Vaddr') or line.startswith('Nm Paddr') or line.startswith('Num Paddr'):
            continue
        if '=== VS_VERSIONINFO ===' in line:
            continue

        # skip summaries
        if re.match('^[0-9]* [a-z]*$', line):
            continue

        # skip opcode lines
        if line.startswith('Special opcode') or line.startswith('op '):
            continue

        # skip ascii strings (those are extracted by a different plugin)
        if 'type=ascii string=' in line or ' ascii ' in line:
            continue

        # keep utf lines, but strip out leading address
        if ('utf8 ' in line) or ('utf16' in line) or ('utf32' in line):
            line = line.split('(', 1)[-1]

        # cut out misc/address info at start of import table line
        if ('NONE' in line) and ('FUNC' in line):
            line = line.split('FUNC')[-1]
            line = line.replace('0 imp.', '')
            line = line.replace('name=', '')
            line = line.strip()
        line = line.split('type=SET_32 ')[-1]

        # cut out address in section table
        if (' -rw' in line) or (' -r-' in line):
            line = ' '.join(line.split()[-2:])  # keep just the last two tokens (r/w and section name)

        # normalize name=numbers (addresses and offsets are too fragile and position dependent)
        line = re.sub('[a-z]+=0x[a-f0-9]+', '', line)
        line = re.sub('[a-z]+=[0-9]+', '', line)
        line = line.strip()
        line = re.sub('^[0-9][0-9a-fx][0-9a-fx -]* ', '', line)  # remove leading numbers

        # skip empty lines
        if not line:
            continue

        features['radare2: '+line] += 1

    return features


def run_clam(filepath, fileinfo=None, temppath='./temp'):
    features = collections.Counter()
    if fileinfo:
        if 'clamav' not in fileinfo:
            fileinfo['clamav'] = None

    skip_lines_containing = [
        'Growing hashtable', 'new capacity:', '-------', 'Ignoring signature', 'size after grow',
        'Initialized', 'Initializing', 'initialized', 'Compiling', 'searching for unrar',
        'unrar support loaded', 'cli_versig:', 'MD5(.tar.gz)', 'in cli_tgzload', 'registered ctx variable',
        'bytecode run finished in', 'performing regex matching', 'Data read:', 'Time: ', 'in cli_cvdload()',
        'Number of certs:', 'bytecode: Parsed, ', 'has logical signature:', 'configuration settings',
        'maxpatlen', 'Freeing hashset', 'JIT compiled', 'executing in interpreter mode', 'Bytecode: disable',
        'running regex', 'growing open-addressing hashtables',
    ]
    skip_lines_starting = [
        'Parsed ', 'Ignoring', 'Scanning', 'cli_loadcrt:', '* Submodule', 'Initializing', 'Loading', 'Loaded',
        'bytecode: Parsed ', 'Skipping', 'line: ', 'Using filter for trie', 'Building regex list',
        'pool memory used', 'check_platform', 'Engine version', 'unknown inst type:', 'OS: ', 'OS ', 'Data scanned: ',
        'Known viruses:', 'Host ', 'cache_check: ', 'Scanned directories: ', 'Cleaning up phishcheck',
        'Freeing phishcheck ', 'cache_add: ', 'Bytecode: mode', 'Bytecode: BC_STARTUP', 'Phishcheck cleaned up',
        'bytecode debug: ', 'in cli_magic_scandesc', 'in cli_scanscript()',
    ]
    skip_lines_ending = [
        'loaded', 'skipped', 'environment detected:', 'no match found', 'PCRE Execution Report End',
        'PCRE Execution Report:'
    ]
    cmd = [
        'clamscan',
        '--archive-verbose',  # Show filenames inside scanned archives
        '--verbose',  # Be verbose
        '--debug',  # Enable libclamav's debug messages
        '--leave-temps',  # Save extracted files
        '--tempdir', temppath,
        filepath
    ]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = proc.communicate()
    for line in stderr.splitlines() + stdout.splitlines():

        # clean the line
        line = line.decode('utf-8', errors='replace')
        line = line.replace('LibClamAV debug: ', '')
        line = line.replace(filepath, '')
        line = line.strip()

        # skip lines that don't describe the file
        if not line:
            continue
        if any([line.startswith(skip) for skip in skip_lines_starting]):
            continue
        if any([line.endswith(skip) for skip in skip_lines_ending]):
            continue
        if any([skip in line for skip in skip_lines_containing]):
            continue
        if line.startswith('Module') and (line.endswith('On') or line.endswith('Off')):
            continue

        # verdict line?
        if line.endswith(' FOUND') or line.endswith(' OK'):
            # verdict, file is OK or clamav found malware
            line = line.split(':', 1)[-1].strip()
            if fileinfo:
                # save this to fileinfo, only if we didn't have a malware verdict before
                if fileinfo['clamav'] is None or fileinfo['clamav'] == 'OK':
                    fileinfo['clamav'] = line.replace('FOUND', '').strip()
        else:
            # in all lines except the verdict, we normalize numbers
            line = normalize_numbers(line)

        features['clamav: '+line] += 1
    return features


def normalize_numbers(line):

    # replace lower digits of large hex numbers with '?'
    templine = line
    for match in re.finditer('(0x[0]{0,15})([1-9a-fA-F][0-9a-fA-F]{2,16})', line):
        number = match.group(1) + match.group(2)
        replacement = match.group(1) + match.group(2)[0] + '?' * (len(match.group(2)) - 1)
        # print('replace "%s" with "%s"' % (number, replacement))
        templine = templine.replace(number, replacement)
    line = templine

    # replace lower digits of large decimal numbers with '?'
    templine = line
    for match in re.finditer(r'\b[1-9][0-9]{2,16}\b', line):
        number = match.group(0)
        replacement = match.group(0)[0] + '?' * (len(match.group(0))-1)
        # print('replace "%s" with "%s"' % (number, replacement))
        templine = templine.replace(number, replacement)
    line = templine

    return line


def test_normalize_numbers():
    test_cases = [
        ('0x666666 0x1 0x22 0x333 0x4444 0x55555 0x01111 0x002222 0x0003333',
         '0x6????? 0x1 0x22 0x3?? 0x4??? 0x5???? 0x01??? 0x002??? 0x0003???'),
        ('666666 1 22 333 4444 55555',
         '6????? 1 22 3?? 4??? 5????')
    ]
    for tc, output in test_cases:
        assert normalize_numbers(tc) == output


if __name__ == '__main__':
    for ln in run_clam(sys.argv[-1]).keys():
        print(ln)
