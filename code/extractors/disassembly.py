import collections
import glob
import os
import re
import subprocess
import sys
import time
import zlib

__version__ = '0.1'
__enabled__ = True

TIMEOUT = 60*3  # typical time over pre-competition corpus is less than 100 sec.  one file took over 800 sec.

NGRAM_LEN = 7  # 7 produced best results
DECIMATION = 10

NGRAM_LEN_SYM = 2
DECIMATION_SYM = 1

NGRAM_LEN_KW = 4  # length of ngrams for keywords
DECIMATION_KW = 2  # decimation for keywords

# Choice of disassembler:
#    objdump is over 20x faster
#    radare2 is more accurate
DISASSEMBLER = 'radare2'  # 'objdump'

g_keyword_regex = None


def run(filepath='', fileinfo=None, temppath='./temp', **kwargs):
    start_time = time.time()
    features = collections.Counter()

    features += run_keywords(filepath, fileinfo)
    features += run_disassembly(filepath, fileinfo)
    features += run_filetype(filepath, fileinfo, temppath)

    print("    %s produced %d features in %0.1f seconds" % (__name__, len(features), time.time() - start_time))
    return features


def run_keywords(filepath='', fileinfo=None):

    features = collections.Counter()

    # supported file type?
    if fileinfo:
        if 'type' in fileinfo:
            if 'text' not in fileinfo['type']:
                return features

    with open(filepath, 'rb') as f:
        content = f.read()
    content = content.decode('utf-8', errors='ignore')

    keywords_found = []
    keyword_regex = load_keywords()
    for match in keyword_regex.finditer(content.lower()):
        kw = match.group(0)
        keywords_found.append(kw)
        features['keyword: '+kw] += 1

    for i in range(len(keywords_found)-NGRAM_LEN_KW):
        ng = ';'.join(keywords_found[i:i+NGRAM_LEN_KW])

        # decimate, don't save all ngrams
        if zlib.crc32(ng.encode('utf-8')) % DECIMATION_KW == 0:
            features[ng] += 1

    return features


def run_disassembly(filepath='', fileinfo=None):

    features = collections.Counter()

    # supported file type?
    if fileinfo:
        if 'type' in fileinfo:
            unsupported = ['text', 'archive', 'data']
            if any([u in fileinfo['type'] for u in unsupported]):
                return features

    assembly = []
    symbols = []

    if DISASSEMBLER == 'objdump':
        cmd = ['objdump', '--disassemble', filepath]
    elif DISASSEMBLER == 'radare2':
        cmd = [
            'r2',  # radare2
            '-A',  # Analyze all (aaa command)
            '-q',  # quiet, don't ask questions and quit when done
            '-c',  # execute following command
            'e scr.color=0;pi @@ *func*;pi @@ *sub*;pi @@ *fcn*',
            # set screen colors off, print instructions for all functions/subroutines
            filepath,
        ]

    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    try:
        stdout, stderr = proc.communicate(timeout=TIMEOUT)
    except subprocess.TimeoutExpired:
        print('    WARNING: Timeout expired for %s.run("%s")' % (__name__, filepath))
        proc.kill()
        stdout, stderr = proc.communicate()
    for line in stdout.splitlines():

        # general cleanup
        line = line.decode('utf-8', errors='replace').strip()

        if DISASSEMBLER == 'objdump':
            tokens = line.split('\t')
            if len(tokens) < 3:
                continue

            # remove address and bytes, keep mnemonic and args
            line = ' '.join(tokens[2:]).strip()

            # remove numbers (addresses and offsets are too fragile and position dependent)
            line = re.sub('0x[a-f0-9]*', '', line)
            line = re.sub('[0-9]*', '', line)

        elif DISASSEMBLER == 'radare2':
            line = re.sub('0x[a-f0-9]*', '', line)

            symbol_match = re.search('sym\.[a-zA-Z0-9_\.]+',line)
            if symbol_match:
                symbols.append(symbol_match.group(0))

        # skip nops
        if line.lower().startswith('nop'):
            continue

        assembly.append(line)

    # N-Gram disassembly
    for i in range(len(assembly)-NGRAM_LEN):
        ng = ';'.join(assembly[i:i+NGRAM_LEN])

        # decimate, don't save all ngrams
        if zlib.crc32(ng.encode('utf-8')) % DECIMATION == 0:
            features['asm ngram: '+ng] += 1

    # N-Gram symbols
    for i in range(len(symbols)-NGRAM_LEN_SYM):
        ng = ';'.join(symbols[i:i+NGRAM_LEN_SYM])

        # decimate, don't save all ngrams
        if zlib.crc32(ng.encode('utf-8')) % DECIMATION_SYM == 0:
            features['sym ngram: '+ng] += 1

    # symbols
    for sym in symbols:
        features['sym: ' + sym] += 1

    # add in any errors:
    for line in stderr.splitlines():
        line = line.decode('utf-8', errors='replace').strip()

        # skips
        if 'TODO: ' in line:
            continue
        if 'esil_neg: unknown' in line:
            continue
        if not line:
            continue
        if line.endswith('[2K'):
            continue

        features[line] += 1

    return features


def run_filetype(filepath, fileinfo, temppath):
    """copy type from fileinfo to features"""
    features = collections.Counter()

    # skip files in temp directory (only record primary file type here)
    if filepath.startswith(temppath):
        return features

    # skip if no fileinfo
    if not fileinfo:
        return features

    features['File type: '+fileinfo['type']] += 1
    for segment in fileinfo['type'].split(','):
        features['File type segment: ' + segment] += 1
        for word in segment.split():
            features['File type word: ' + word] += 1

    return features


def load_keywords():

    global g_keyword_regex

    if g_keyword_regex is not None:
        return g_keyword_regex

    keywords_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'keywords')
    keyword_files = glob.glob(os.path.join(keywords_path, 'keywords*.txt'))

    keywords = []
    for keyword_file in keyword_files:
        with open(keyword_file, 'rt') as f:
            content = f.read()
        for line in content.splitlines():
            keyword = line.split('#', 1)[0].strip()  # remove any comment
            if not keyword:
                continue
            keyword = keyword.lower()
            if not keyword.startswith('<'):
                keyword = '\\b' + keyword + '\\b'  # slash 'b' is regex for word boundary
            keywords.append(keyword)

    g_keyword_regex = re.compile('|'.join(keywords))
    return g_keyword_regex


if __name__ == '__main__':
    if len(sys.argv) < 2:
        print('Usage: %s filepath' % sys.argv[0])
        exit(-1)
    features = run(sys.argv[1])
    for f in features:
        print(f)
